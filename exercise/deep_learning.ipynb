{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "models = tf.keras.models\n",
    "layers = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hungh\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "# Conv Layer 1\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(720, 480, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Conv Layer 2\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Conv Layer 3\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Conv Layer 4\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flattening the layers\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Fully Connected Layer\n",
    "model.add(layers.Dense(720, activation='relu'))\n",
    "\n",
    "# Output Layer\n",
    "model.add(layers.Dense(1, activation='sigmoid'))  # 이진 분류이므로 sigmoid 사용\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sixtick\n",
      "\tpytyon\n",
      "\t\teasy.py\n",
      "easy.py loaded\n"
     ]
    }
   ],
   "source": [
    "# import sixtick.python.easy as s\n",
    "# image_path_arr = ['../image/KEMP_IMG_DATA_1.png', '../image/KEMP_IMG_DATA_Error_2.png', '../image/KEMP_IMG_DATA_Error_12.png']\n",
    "# image_arr_weight = [8,1,1]\n",
    "# path = s.sample(image_path_arr, 1, counts=image_arr_weight)\n",
    "# x_train = []\n",
    "# y_train = []\n",
    "# for i in range(20):\n",
    "#     path = s.sample(image_path_arr, 1, counts=image_arr_weight)[0]\n",
    "#     isok = not 'Error' in path \n",
    "#     x_train.append(s.cv.imread(path, s.cv.IMREAD_GRAYSCALE))\n",
    "#     y_train.append(isok)\n",
    "# x_train = s.np.array(x_train)\n",
    "# y_train = s.np.array(y_train)\n",
    "\n",
    "# x_val = []\n",
    "# y_val = []\n",
    "# for i in range(10):\n",
    "#     path = s.sample(image_path_arr, 1, counts=image_arr_weight)[0]\n",
    "#     isok = not 'Error' in path \n",
    "#     x_val.append(s.cv.imread(path, s.cv.IMREAD_GRAYSCALE))\n",
    "#     y_val.append(isok)\n",
    "# x_val = s.np.array(x_val)\n",
    "# y_val = s.np.array(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sixtick.python.easy as s\n",
    "def get_train_data_kemp(to_gray = False) :\n",
    "    image_path_arr = ['../image/KEMP_IMG_DATA_1.png', '../image/KEMP_IMG_DATA_Error_2.png', '../image/KEMP_IMG_DATA_Error_12.png']\n",
    "    image_arr_weight = [8,1,1]\n",
    "    path = s.sample(image_path_arr, 1, counts=image_arr_weight)[0]\n",
    "    if to_gray : \n",
    "        x_train = s.cv.imread(path)\n",
    "        y_train = not 'Error' in path\n",
    "        return x_train, s.np.array([y_train])\n",
    "    else : \n",
    "        x_train = s.cv.imread(path, s.cv.IMREAD_GRAYSCALE)\n",
    "        y_train = not 'Error' in path\n",
    "        return x_train.reshape(-1, 720, 480), s.np.array([y_train]) #s.np.array([int(y_train)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x, y =  get_train_data_kemp()\n",
    "# x.reshape(-1, 720,480).shape\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3.2648 - val_accuracy: 0.0000e+00 - val_loss: 1959.6205\n"
     ]
    }
   ],
   "source": [
    "# # 모델 학습\n",
    "# x_train, y_train = get_train_data_kemp()\n",
    "# x_val, y_val = get_train_data_kemp()\n",
    "# history = model.fit(\n",
    "#     x_train,  # 입력 데이터 (훈련 데이터)\n",
    "#     y_train,  # 출력 데이터 (훈련 데이터의 레이블)\n",
    "#     # steps_per_epoch=100,\n",
    "#     epochs=1,\n",
    "#     validation_data=(x_val, y_val)  # 검증 데이터와 검증 레이블\n",
    "#     # validation_steps=50\n",
    "#     # ,verbose=1\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rc('font', family='gulim')\n",
    "history_df = pd.DataFrame()\n",
    "\n",
    "# plt.ion()  # Interactive 모드를 켬 (실시간 업데이트)\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "for i in range(50):\n",
    "    x_train, y_train = get_train_data_kemp()\n",
    "    x_val, y_val = get_train_data_kemp()\n",
    "    # print(len(history))\n",
    "    if len(history_df) == 50:\n",
    "        history_df.drop(0, inplace=True)\n",
    "        history_df.reset_index(drop=True, inplace=True)\n",
    "    history = model.fit(\n",
    "        x_train,  # 입력 데이터 (훈련 데이터)\n",
    "        y_train,  # 출력 데이터 (훈련 데이터의 레이블)\n",
    "        # steps_per_epoch=100,\n",
    "        epochs=1,\n",
    "        validation_data=(x_val, y_val)  # 검증 데이터와 검증 레이블\n",
    "        # validation_steps=50\n",
    "        ,verbose=0\n",
    "    )\n",
    "    if len(history_df) == 0 :\n",
    "        history_df = pd.DataFrame(history.history)\n",
    "        history_df['val_accuracy_mean'] = history_df['val_accuracy']\n",
    "        history_df['val_loss_mean'] = history_df['val_loss']\n",
    "    else :\n",
    "        history_df = pd.concat([history_df, pd.DataFrame(history.history)], axis=0)\n",
    "        history_df.reset_index(drop=True, inplace=True)\n",
    "        history_df.loc[i, 'val_accuracy_mean'] = history_df['val_accuracy'].mean()\n",
    "        history_df.loc[i, 'val_loss_mean'] = history_df['val_loss'].mean()\n",
    "    \n",
    "    # ax.clear()  # 기존 플롯을 지움\n",
    "    plt.scatter(range(len(history_df)), history_df['val_accuracy'])\n",
    "    plt.scatter(range(len(history_df)), history_df['val_loss'])\n",
    "    plt.plot(range(len(history_df)), history_df['val_accuracy_mean'], label=f'val_accuracy_mean {history_df.loc[i, 'val_accuracy_mean']:.2f}')\n",
    "    plt.plot(range(len(history_df)), history_df['val_loss_mean'], label=f'val_loss_mean {history_df.loc[i, 'val_loss_mean']:.2f}')\n",
    "    plt.xlabel('COUNT')\n",
    "\n",
    "    # plt.draw()\n",
    "    # plt.pause(0.1)\n",
    "    plt.title('learning images')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(i+1)\n",
    "    clear_output(wait=True)\n",
    "\n",
    "# plt.ioff()  # Interactive 모드 끔\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('learning150.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 저장된 모델 불러오기, 실제 이미지 넣어보기, 이미지를 보여주면서 검증하기, 이미지에 O X 표시하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "loss_arr = []\n",
    "accuracy_arr = []\n",
    "for i in range(100):\n",
    "    x, y = get_train_data_kemp()\n",
    "    # predictions = model.predict(x)\n",
    "    # print(predictions, y)\n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    loss_arr.append(round(loss, 1))\n",
    "    accuracy_arr.append(round(accuracy, 1))\n",
    "    # print(round(loss, 2), accuracy)\n",
    "# print('Predictions:')\n",
    "# print(np.round(predictions))\n",
    "print(np.mean(loss_arr), np.mean(accuracy_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 237ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 243ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 244ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 259ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 253ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 250ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 258ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 240ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 251ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 256ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 269ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 257ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 262ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 265ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 255ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 268ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "(1, 720, 480)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# 이미지 띄우면서 검증하기\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import sixtick.python.easy as s\n",
    "loss_arr = []\n",
    "accuracy_arr = []\n",
    "count = 100\n",
    "for i in range(count):\n",
    "    x_org, y = get_train_data_kemp(True)\n",
    "    \n",
    "    image_name = f'img_OK {i}'\n",
    "    if not y :\n",
    "        image_name = f'img_BAD {i}'\n",
    "    #cv.imshow(image_name, x)\n",
    "    s.image_center_show(image_name, x_org)\n",
    "\n",
    "    x = s.cv.cvtColor(x_org, s.cv.COLOR_BGR2GRAY).reshape(-1, 720, 480)\n",
    "    print(x.shape)\n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    if accuracy == 1 and y == True :\n",
    "        # cv.drawMarker(x_org, (20,20), color=(0,0,255), markerType=cv.marker, markerSize=20)\n",
    "        cv.circle(x_org, (480//2,720//2), radius=150, thickness=20, color=(255,0,0)) # 원\n",
    "    elif accuracy == 1 and y == False: \n",
    "        cv.drawMarker(x_org, (480//2,720//2), color=(0,0,255), markerType=cv.MARKER_TILTED_CROSS, markerSize=300, thickness=20)\n",
    "    else : \n",
    "        cv.drawMarker(x_org, (480//2,720//2), color=(0,255,0), markerType=cv.MARKER_STAR, markerSize=300, thickness=20)\n",
    "    s.image_center_show(image_name, x_org)\n",
    "    loss_arr.append(round(loss, 1))\n",
    "    accuracy_arr.append(round(accuracy, 1))\n",
    "    cv.waitKey(500)\n",
    "\n",
    "\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "print(np.mean(loss_arr), np.mean(accuracy_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    accuracy          loss  val_accuracy      val_loss\n",
      "0        1.0  0.000000e+00           1.0  0.000000e+00\n",
      "1        1.0  0.000000e+00           1.0  0.000000e+00\n",
      "2        1.0  0.000000e+00           0.0  7.846743e+03\n",
      "3        1.0  0.000000e+00           1.0  0.000000e+00\n",
      "4        1.0  0.000000e+00           1.0  0.000000e+00\n",
      "5        1.0  0.000000e+00           1.0  0.000000e+00\n",
      "6        0.0  1.443919e+04           1.0  0.000000e+00\n",
      "7        0.0  8.276235e+03           1.0  0.000000e+00\n",
      "8        1.0  0.000000e+00           1.0  0.000000e+00\n",
      "9        0.0  5.173548e+02           0.0  5.488678e+02\n",
      "10       0.0  5.488678e+02           0.0  1.930887e+02\n",
      "11       1.0  0.000000e+00           1.0  4.250103e-34\n",
      "12       1.0  1.014383e-19           1.0  0.000000e+00\n",
      "13       1.0  0.000000e+00           1.0  0.000000e+00\n",
      "14       1.0  0.000000e+00           1.0  0.000000e+00\n",
      "15       1.0  0.000000e+00           1.0  0.000000e+00\n",
      "16       0.0  5.416466e+02           1.0  0.000000e+00\n",
      "17       0.0  2.394739e+02           1.0  6.102829e-05\n",
      "18       1.0  6.102829e-05           1.0  9.666911e-27\n",
      "19       0.0  3.475569e+01           0.0  1.864028e+01\n",
      "20       0.0  1.864028e+01           1.0  3.743171e-02\n",
      "21       1.0  3.743171e-02           1.0  9.956209e-12\n",
      "22       1.0  9.956209e-12           0.0  1.570720e+00\n",
      "23       1.0  3.474897e-20           1.0  1.394661e-26\n",
      "24       1.0  1.394661e-26           1.0  8.189644e-31\n",
      "25       1.0  8.189644e-31           1.0  4.155036e-36\n",
      "26       1.0  4.155036e-36           1.0  0.000000e+00\n",
      "27       1.0  0.000000e+00           1.0  0.000000e+00\n",
      "28       1.0  0.000000e+00           1.0  0.000000e+00\n",
      "29       1.0  0.000000e+00           1.0  0.000000e+00\n",
      "30       0.0  7.162280e+01           1.0  1.199778e-30\n",
      "31       1.0  1.199778e-30           1.0  3.637861e-04\n",
      "32       1.0  3.637861e-04           0.0  3.815469e+01\n",
      "33       0.0  3.815469e+01           1.0  4.131404e-30\n",
      "34       1.0  5.645857e-01           1.0  3.360009e-17\n",
      "35       1.0  3.360009e-17           1.0  2.862794e-26\n",
      "36       1.0  3.671281e-08           1.0  9.111388e-32\n",
      "37       1.0  9.111388e-32           1.0  5.047001e-36\n",
      "38       1.0  5.047001e-36           1.0  0.000000e+00\n",
      "39       1.0  0.000000e+00           1.0  0.000000e+00\n",
      "40       1.0  0.000000e+00           0.0  1.403571e+01\n",
      "41       1.0  0.000000e+00           1.0  0.000000e+00\n",
      "42       0.0  5.647604e+01           1.0  0.000000e+00\n",
      "43       1.0  0.000000e+00           1.0  2.497850e-33\n",
      "44       1.0  2.497850e-33           0.0  1.356491e+00\n",
      "45       1.0  1.029869e-27           1.0  2.035589e-22\n",
      "46       1.0  2.035589e-22           1.0  1.796063e-17\n",
      "47       1.0  1.796063e-17           1.0  7.411031e-19\n",
      "48       1.0  6.570390e-13           1.0  1.288318e-08\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history_df.drop(0, inplace=True)\n",
    "history_df.reset_index(drop=True, inplace=True)\n",
    "# history_df.drop('index',axis=1, inplace=True)\n",
    "len(history_df)\n",
    "print(history_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A   B\n",
      "0  1   4\n",
      "1  2   5\n",
      "2  3   6\n",
      "0  7  10\n",
      "1  8  11\n",
      "2  9  12\n",
      "   A  B  A   B\n",
      "0  1  4  7  10\n",
      "1  2  5  8  11\n",
      "2  3  6  9  12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 예시 DataFrame 두 개\n",
    "df1 = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6]\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'A': [7, 8, 9],\n",
    "    'B': [10, 11, 12]\n",
    "})\n",
    "\n",
    "# 1. 수직으로 결합 (행 추가)\n",
    "df_vertical = pd.concat([df1, df2], axis=0)\n",
    "print(df_vertical)\n",
    "\n",
    "# 2. 수평으로 결합 (열 추가)\n",
    "df_horizontal = pd.concat([df1, df2], axis=1)\n",
    "print(df_horizontal)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
