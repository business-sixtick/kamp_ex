{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# models = tf.keras.models\n",
    "# layers = tf.keras.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "models = tf.keras.models\n",
    "layers = tf.keras.layers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Conv Layer 1\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(720, 480, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2))) # 구역에서 높은거 추출\n",
    "# Conv Layer 2\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu')) # 커널 개수 64 커널 사이즈 3*3\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "# Conv Layer 3\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "# Conv Layer 4\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "# Flattening the layers\n",
    "model.add(layers.Flatten()) # 1차원으로 변형\n",
    "# Fully Connected Layer\n",
    "model.add(layers.Dense(720, activation='relu'))\n",
    "model.add(layers.Dropout(0.5)) # 드롭아웃 50%\n",
    "# Output Layer\n",
    "model.add(layers.Dense(1, activation='sigmoid'))  # 이진 분류이므로 sigmoid 사용\n",
    "# 모델 컴파일\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sixtick\n",
      "\tpytyon\n",
      "\t\teasy.py\n",
      "easy.py loaded\n"
     ]
    }
   ],
   "source": [
    "# import sixtick.python.easy as s\n",
    "# image_path_arr = ['../image/KEMP_IMG_DATA_1.png', '../image/KEMP_IMG_DATA_Error_2.png', '../image/KEMP_IMG_DATA_Error_12.png']\n",
    "# image_arr_weight = [8,1,1]\n",
    "# path = s.sample(image_path_arr, 1, counts=image_arr_weight)\n",
    "# x_train = []\n",
    "# y_train = []\n",
    "# for i in range(20):\n",
    "#     path = s.sample(image_path_arr, 1, counts=image_arr_weight)[0]\n",
    "#     isok = not 'Error' in path \n",
    "#     x_train.append(s.cv.imread(path, s.cv.IMREAD_GRAYSCALE))\n",
    "#     y_train.append(isok)\n",
    "# x_train = s.np.array(x_train)\n",
    "# y_train = s.np.array(y_train)\n",
    "\n",
    "# x_val = []\n",
    "# y_val = []\n",
    "# for i in range(10):\n",
    "#     path = s.sample(image_path_arr, 1, counts=image_arr_weight)[0]\n",
    "#     isok = not 'Error' in path \n",
    "#     x_val.append(s.cv.imread(path, s.cv.IMREAD_GRAYSCALE))\n",
    "#     y_val.append(isok)\n",
    "# x_val = s.np.array(x_val)\n",
    "# y_val = s.np.array(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sixtick.python.easy as s\n",
    "# def get_train_data_kemp(to_gray = False) :\n",
    "#     image_path_arr = ['../image/KEMP_IMG_DATA_1.png', '../image/KEMP_IMG_DATA_Error_2.png', '../image/KEMP_IMG_DATA_Error_12.png']\n",
    "#     image_arr_weight = [8,1,1]\n",
    "#     path = s.sample(image_path_arr, 1, counts=image_arr_weight)[0]\n",
    "#     if to_gray : \n",
    "#         x_train = s.cv.imread(path)\n",
    "#         y_train = not 'Error' in path\n",
    "#         return x_train, s.np.array([y_train])\n",
    "#     else : \n",
    "#         x_train = s.cv.imread(path, s.cv.IMREAD_GRAYSCALE)\n",
    "#         y_train = not 'Error' in path\n",
    "#         return x_train.reshape(-1, 720, 480), s.np.array([y_train]) #s.np.array([int(y_train)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "easy.py loaded\n"
     ]
    }
   ],
   "source": [
    "import sixtick.python.easy as s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sixtick\n",
      "\tpytyon\n",
      "\t\teasy.py\n",
      "easy.py loaded\n"
     ]
    }
   ],
   "source": [
    "import sixtick.python.easy as s\n",
    "def get_train_data_kemp(to_gray = True) :\n",
    "    image_path_arr = ['../image/KEMP_IMG_DATA_1.png', '../image/KEMP_IMG_DATA_Error_2.png', '../image/KEMP_IMG_DATA_Error_12.png']\n",
    "    image_arr_weight = [6,2,2]\n",
    "    # path = s.sample(image_path_arr, 1, counts=image_arr_weight)[0]  #choices\n",
    "    path = s.choices(image_path_arr, k=1, weights=image_arr_weight)[0]  #choices\n",
    "    if not to_gray : \n",
    "        x_train = s.cv.imread(path)\n",
    "\n",
    "        height, width = x_train.shape[:2]\n",
    "        angle = s.random() * 10 - 5\n",
    "        rotation_matrix = s.cv.getRotationMatrix2D((width / 2, height / 2), angle, 1)\n",
    "        rotation_matrix[0][2] += s.random() * 72 - 36 # 세로 축 이동\n",
    "        rotation_matrix[1][2] += s.random() * 48 - 24 # 가로 축 이동\n",
    "        # print(rotation_matrix, type(rotation_matrix), rotation_matrix[0][2])\n",
    "        x_train = s.cv.warpAffine(x_train, rotation_matrix, (width, height))\n",
    "\n",
    "        y_train = not 'Error' in path\n",
    "        return x_train, s.np.array([y_train])\n",
    "    else : \n",
    "        x_train = s.cv.imread(path, s.cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "        height, width = x_train.shape\n",
    "        angle = s.random() * 10 - 5\n",
    "        rotation_matrix = s.cv.getRotationMatrix2D((width / 2, height / 2), angle, 1)\n",
    "        rotation_matrix[0][2] += s.random() * 72 - 36 # 세로 축 이동\n",
    "        rotation_matrix[1][2] += s.random() * 48 - 24 # 가로 축 이동\n",
    "        # print(rotation_matrix, type(rotation_matrix), rotation_matrix[0][2])\n",
    "        x_train = s.cv.warpAffine(x_train, rotation_matrix, (width, height))\n",
    "\n",
    "        y_train = not 'Error' in path\n",
    "        return x_train.reshape(-1, 720, 480), s.np.array([y_train]) #s.np.array([int(y_train)])\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1]\n",
      "[3]\n",
      "[4]\n",
      "[3]\n",
      "[1]\n",
      "[5]\n",
      "[3]\n",
      "[3]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(s.choices([1,2,3,4,5], weights=[5,1,1,1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x, y =  get_train_data_kemp()\n",
    "# x.reshape(-1, 720,480).shape\n",
    "# y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.0000e+00 - loss: 3.2648 - val_accuracy: 0.0000e+00 - val_loss: 1959.6205\n"
     ]
    }
   ],
   "source": [
    "# # 모델 학습\n",
    "# x_train, y_train = get_train_data_kemp()\n",
    "# x_val, y_val = get_train_data_kemp()\n",
    "# history = model.fit(\n",
    "#     x_train,  # 입력 데이터 (훈련 데이터)\n",
    "#     y_train,  # 출력 데이터 (훈련 데이터의 레이블)\n",
    "#     # steps_per_epoch=100,\n",
    "#     epochs=1,\n",
    "#     validation_data=(x_val, y_val)  # 검증 데이터와 검증 레이블\n",
    "#     # validation_steps=50\n",
    "#     # ,verbose=1\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rc('font', family='gulim')\n",
    "history_df = pd.DataFrame()\n",
    "\n",
    "# plt.ion()  # Interactive 모드를 켬 (실시간 업데이트)\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "repeat = 50\n",
    "\n",
    "for i in range(repeat):\n",
    "    x_train, y_train = get_train_data_kemp()\n",
    "    x_val, y_val = get_train_data_kemp()\n",
    "    # print(len(history))\n",
    "    if len(history_df) == 50:\n",
    "        history_df.drop(0, inplace=True)\n",
    "        history_df.reset_index(drop=True, inplace=True)\n",
    "    history = model.fit(\n",
    "        x_train,  # 입력 데이터 (훈련 데이터)\n",
    "        y_train,  # 출력 데이터 (훈련 데이터의 레이블)\n",
    "        # steps_per_epoch=100,\n",
    "        epochs=1,\n",
    "        validation_data=(x_val, y_val)  # 검증 데이터와 검증 레이블\n",
    "        # validation_steps=50\n",
    "        ,verbose=0\n",
    "    )\n",
    "    if len(history_df) == 0 :\n",
    "        history_df = pd.DataFrame(history.history)\n",
    "        history_df['val_accuracy_mean'] = history_df['val_accuracy']\n",
    "        history_df['val_loss_mean'] = history_df['val_loss']\n",
    "    else :\n",
    "        history_df = pd.concat([history_df, pd.DataFrame(history.history)], axis=0)\n",
    "        history_df.reset_index(drop=True, inplace=True)\n",
    "        history_df.loc[i, 'val_accuracy_mean'] = history_df['val_accuracy'].mean()\n",
    "        history_df.loc[i, 'val_loss_mean'] = history_df['val_loss'].mean()\n",
    "    \n",
    "    # ax.clear()  # 기존 플롯을 지움\n",
    "    plt.scatter(range(len(history_df)), history_df['val_accuracy'])\n",
    "    plt.scatter(range(len(history_df)), history_df['val_loss'])\n",
    "    plt.plot(range(len(history_df)), history_df['val_accuracy_mean'], label=f'val_accuracy_mean {history_df.loc[i, \"val_accuracy_mean\"]:.2f}')\n",
    "    plt.plot(range(len(history_df)), history_df['val_loss_mean'], label=f'val_loss_mean {history_df.loc[i, \"val_loss_mean\"]:.2f}')\n",
    "    plt.xlabel('COUNT')\n",
    "\n",
    "    # plt.draw()\n",
    "    # plt.pause(0.1)\n",
    "    plt.title('learning images')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print(i+1)\n",
    "    clear_output(wait=True)\n",
    "\n",
    "# plt.ioff()  # Interactive 모드 끔\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df.loc[0, 'val_accuracy_mean'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:\\source\\learning_kamp.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models.load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 718, 478, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 359, 239, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 357, 237, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 178, 118, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 176, 116, 128)     73856     \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 88, 58, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 86, 56, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 43, 28, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 154112)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 720)               110961360 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 720)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 721       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 111,202,337\n",
      "Trainable params: 111,202,337\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO 저장된 모델 불러오기, 실제 이미지 넣어보기, 이미지를 보여주면서 검증하기, 이미지에 O X 표시하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 190ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 216ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 226ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 195ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 235ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 207ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 270ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 233ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 221ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 224ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 217ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 211ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 204ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 229ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 232ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 252ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 239ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 196ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 201ms/step - accuracy: 1.0000 - loss: 1.1166e-25\n",
      "0.0 1.0\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# loss_arr = []\n",
    "# accuracy_arr = []\n",
    "# for i in range(100):\n",
    "#     x, y = get_train_data_kemp()\n",
    "#     # predictions = model.predict(x)\n",
    "#     # print(predictions, y)\n",
    "#     loss, accuracy = model.evaluate(x, y)\n",
    "#     loss_arr.append(round(loss, 1))\n",
    "#     accuracy_arr.append(round(accuracy, 1))\n",
    "#     # print(round(loss, 2), accuracy)\n",
    "# # print('Predictions:')\n",
    "# # print(np.round(predictions))\n",
    "# print(np.mean(loss_arr), np.mean(accuracy_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 252ms/step - loss: 4.1513e-17 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.2940e-07 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 1.0449e-08 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.5638e-15 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 1.3010e-15 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 1.1338e-09 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 7.5951e-13 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.8655e-12 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.9553e-18 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 9.5058e-12 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.1945e-15 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 2.9073e-14 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 1.1453e-19 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.5690e-17 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 5.0093e-14 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.7780e-14 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 2.4679e-21 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 1.3343e-14 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 3.1169e-20 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 1.8704e-17 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 3.8709e-10 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.6944e-17 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 188ms/step - loss: 5.7273e-11 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 8.5772e-05 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 9.0718e-15 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 5.9233e-16 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 3.1617e-13 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.8467e-20 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 8.2748e-19 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 7.5716e-16 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.8380e-14 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 7.4119e-05 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.4712e-10 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 6.7502e-12 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 3.1767e-12 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 1.7595e-13 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 7.1373e-12 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 4.9991e-13 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.5955e-11 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 6.4125e-12 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 5.6393e-12 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 2.7702e-16 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 5.3241e-05 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 2.4768e-08 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.0210e-09 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 237ms/step - loss: 8.2998e-11 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 4.8003e-16 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 1.5167e-12 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 1.6599e-15 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 3.3099e-17 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 7.6713e-13 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 7.5806e-17 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 3.1967e-12 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 7.2441e-18 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.7807e-13 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 3.0200e-10 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 230ms/step - loss: 6.0163e-18 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 3.5554e-13 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 5.8778e-09 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.1185e-13 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 6.8928e-11 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1890e-09 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 2.2584e-07 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2976 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 1.0207e-16 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 7.5635e-14 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 2.8721e-09 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 227ms/step - loss: 1.7932e-08 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 6.9621e-15 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 2.2193e-17 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 7.7305e-14 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.9163e-12 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.6292e-11 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.7378e-09 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 7.4419e-15 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 6.4213e-15 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.4426e-13 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 1.9475e-05 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 2.4265e-06 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 242ms/step - loss: 4.0525e-18 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 2.8229e-16 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 2.2574e-13 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 2.0268e-08 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 2.4345e-09 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.7490e-15 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 3.4983e-13 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 1.6559e-18 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 6.8088e-16 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 7.2350e-16 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 210ms/step - loss: 8.8807e-16 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 3.4616e-14 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 7.9188e-08 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 8.7499e-17 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 5.7901e-11 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 2.9060e-10 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 9.2599e-11 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 1.3223e-10 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 1.1102e-12 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 203ms/step - loss: 7.3386e-15 - accuracy: 1.0000\n",
      "(1, 720, 480)\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 6.1216e-10 - accuracy: 1.0000\n",
      "0.003 1.0\n"
     ]
    }
   ],
   "source": [
    "# 이미지 띄우면서 검증하기\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import sixtick.python.easy as s\n",
    "loss_arr = []\n",
    "accuracy_arr = []\n",
    "count = 100\n",
    "wait_time = 500\n",
    "image_name = ''\n",
    "for i in range(count):\n",
    "    x_org, y = get_train_data_kemp(False)\n",
    "    old_name = ''\n",
    "    if image_name != '':\n",
    "        old_name = image_name\n",
    "    image_name = f'img_OK {i}'\n",
    "    if not y :\n",
    "        image_name = f'img_BAD {i}'\n",
    "    #cv.imshow(image_name, x)\n",
    "    # s.image_center_show(image_name, x_org)\n",
    "\n",
    "    x = s.cv.cvtColor(x_org, s.cv.COLOR_BGR2GRAY).reshape(-1, 720, 480)\n",
    "    print(x.shape)\n",
    "    loss, accuracy = model.evaluate(x, y)\n",
    "    if accuracy == 1 and y == True :\n",
    "        # cv.drawMarker(x_org, (20,20), color=(0,0,255), markerType=cv.marker, markerSize=20)\n",
    "        cv.circle(x_org, (480//2,720//2), radius=150, thickness=20, color=(255,0,0)) # 원\n",
    "    elif accuracy == 1 and y == False: \n",
    "        cv.drawMarker(x_org, (480//2,720//2), color=(0,0,255), markerType=cv.MARKER_TILTED_CROSS, markerSize=300, thickness=20)\n",
    "    else : \n",
    "        cv.drawMarker(x_org, (480//2,720//2), color=(0,255,0), markerType=cv.MARKER_STAR, markerSize=300, thickness=20)\n",
    "    \n",
    "    if old_name != '':\n",
    "        cv.destroyWindow(old_name)\n",
    "    s.image_center_show(image_name, x_org)\n",
    "    loss_arr.append(round(loss, 1))\n",
    "    accuracy_arr.append(round(accuracy, 1))\n",
    "    cv.waitKey(wait_time)\n",
    "    # if cv.waitKey(wait_time) == ord('q'):\n",
    "    #     break\n",
    "    \n",
    "\n",
    "\n",
    "cv.destroyAllWindows()\n",
    "# clear_output(wait=True)\n",
    "print(np.mean(loss_arr), np.mean(accuracy_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    accuracy          loss  val_accuracy      val_loss\n",
      "0        1.0  0.000000e+00           1.0  0.000000e+00\n",
      "1        1.0  0.000000e+00           1.0  0.000000e+00\n",
      "2        1.0  0.000000e+00           0.0  7.846743e+03\n",
      "3        1.0  0.000000e+00           1.0  0.000000e+00\n",
      "4        1.0  0.000000e+00           1.0  0.000000e+00\n",
      "5        1.0  0.000000e+00           1.0  0.000000e+00\n",
      "6        0.0  1.443919e+04           1.0  0.000000e+00\n",
      "7        0.0  8.276235e+03           1.0  0.000000e+00\n",
      "8        1.0  0.000000e+00           1.0  0.000000e+00\n",
      "9        0.0  5.173548e+02           0.0  5.488678e+02\n",
      "10       0.0  5.488678e+02           0.0  1.930887e+02\n",
      "11       1.0  0.000000e+00           1.0  4.250103e-34\n",
      "12       1.0  1.014383e-19           1.0  0.000000e+00\n",
      "13       1.0  0.000000e+00           1.0  0.000000e+00\n",
      "14       1.0  0.000000e+00           1.0  0.000000e+00\n",
      "15       1.0  0.000000e+00           1.0  0.000000e+00\n",
      "16       0.0  5.416466e+02           1.0  0.000000e+00\n",
      "17       0.0  2.394739e+02           1.0  6.102829e-05\n",
      "18       1.0  6.102829e-05           1.0  9.666911e-27\n",
      "19       0.0  3.475569e+01           0.0  1.864028e+01\n",
      "20       0.0  1.864028e+01           1.0  3.743171e-02\n",
      "21       1.0  3.743171e-02           1.0  9.956209e-12\n",
      "22       1.0  9.956209e-12           0.0  1.570720e+00\n",
      "23       1.0  3.474897e-20           1.0  1.394661e-26\n",
      "24       1.0  1.394661e-26           1.0  8.189644e-31\n",
      "25       1.0  8.189644e-31           1.0  4.155036e-36\n",
      "26       1.0  4.155036e-36           1.0  0.000000e+00\n",
      "27       1.0  0.000000e+00           1.0  0.000000e+00\n",
      "28       1.0  0.000000e+00           1.0  0.000000e+00\n",
      "29       1.0  0.000000e+00           1.0  0.000000e+00\n",
      "30       0.0  7.162280e+01           1.0  1.199778e-30\n",
      "31       1.0  1.199778e-30           1.0  3.637861e-04\n",
      "32       1.0  3.637861e-04           0.0  3.815469e+01\n",
      "33       0.0  3.815469e+01           1.0  4.131404e-30\n",
      "34       1.0  5.645857e-01           1.0  3.360009e-17\n",
      "35       1.0  3.360009e-17           1.0  2.862794e-26\n",
      "36       1.0  3.671281e-08           1.0  9.111388e-32\n",
      "37       1.0  9.111388e-32           1.0  5.047001e-36\n",
      "38       1.0  5.047001e-36           1.0  0.000000e+00\n",
      "39       1.0  0.000000e+00           1.0  0.000000e+00\n",
      "40       1.0  0.000000e+00           0.0  1.403571e+01\n",
      "41       1.0  0.000000e+00           1.0  0.000000e+00\n",
      "42       0.0  5.647604e+01           1.0  0.000000e+00\n",
      "43       1.0  0.000000e+00           1.0  2.497850e-33\n",
      "44       1.0  2.497850e-33           0.0  1.356491e+00\n",
      "45       1.0  1.029869e-27           1.0  2.035589e-22\n",
      "46       1.0  2.035589e-22           1.0  1.796063e-17\n",
      "47       1.0  1.796063e-17           1.0  7.411031e-19\n",
      "48       1.0  6.570390e-13           1.0  1.288318e-08\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history_df.drop(0, inplace=True)\n",
    "history_df.reset_index(drop=True, inplace=True)\n",
    "# history_df.drop('index',axis=1, inplace=True)\n",
    "len(history_df)\n",
    "print(history_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A   B\n",
      "0  1   4\n",
      "1  2   5\n",
      "2  3   6\n",
      "0  7  10\n",
      "1  8  11\n",
      "2  9  12\n",
      "   A  B  A   B\n",
      "0  1  4  7  10\n",
      "1  2  5  8  11\n",
      "2  3  6  9  12\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 예시 DataFrame 두 개\n",
    "df1 = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6]\n",
    "})\n",
    "\n",
    "df2 = pd.DataFrame({\n",
    "    'A': [7, 8, 9],\n",
    "    'B': [10, 11, 12]\n",
    "})\n",
    "\n",
    "# 1. 수직으로 결합 (행 추가)\n",
    "df_vertical = pd.concat([df1, df2], axis=0)\n",
    "print(df_vertical)\n",
    "\n",
    "# 2. 수평으로 결합 (열 추가)\n",
    "df_horizontal = pd.concat([df1, df2], axis=1)\n",
    "print(df_horizontal)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
